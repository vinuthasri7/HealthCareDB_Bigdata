{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65b46db1-d94c-4518-b7b0-bc8d63854053",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+--------------------+-------------+----------------+\n|Patient_ID|Age|Gender|            Symptoms|Symptom_Count|         Disease|\n+----------+---+------+--------------------+-------------+----------------+\n|         1| 29|  Male|fever, back pain,...|            3|         Allergy|\n|         2| 76|Female|insomnia, back pa...|            3|Thyroid Disorder|\n|         3| 78|  Male|sore throat, vomi...|            3|       Influenza|\n|         4| 58| Other|blurred vision, d...|            4|          Stroke|\n|         5| 55|Female|swelling, appetit...|            3|   Heart Disease|\n+----------+---+------+--------------------+-------------+----------------+\nonly showing top 5 rows\nroot\n |-- Patient_ID: long (nullable = true)\n |-- Age: long (nullable = true)\n |-- Gender: string (nullable = true)\n |-- Symptoms: string (nullable = true)\n |-- Symptom_Count: long (nullable = true)\n |-- Disease: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Try with catalog.schema first\n",
    "df_raw = spark.table(\"final_exam_cluster.default.raw_healthcare\")\n",
    "df_raw.show(5)\n",
    "df_raw.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4abe992-c567-4e6c-b397-46c6bfb8faa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+--------------------+-------------+----------------+-----------+--------------+\n|Patient_ID|Age|Gender|            Symptoms|Symptom_count|         Disease|  age_group|severity_level|\n+----------+---+------+--------------------+-------------+----------------+-----------+--------------+\n|         1| 29|  Male|fever, back pain,...|            3|         Allergy|      Adult|      Moderate|\n|         2| 76|Female|insomnia, back pa...|            3|Thyroid Disorder|     Senior|      Moderate|\n|         3| 78|  Male|sore throat, vomi...|            3|       Influenza|     Senior|      Moderate|\n|         4| 58| Other|blurred vision, d...|            4|          Stroke|Middle-aged|      Moderate|\n|         5| 55|Female|swelling, appetit...|            3|   Heart Disease|Middle-aged|      Moderate|\n+----------+---+------+--------------------+-------------+----------------+-----------+--------------+\nonly showing top 5 rows\nroot\n |-- Patient_ID: long (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Gender: string (nullable = true)\n |-- Symptoms: string (nullable = true)\n |-- Symptom_count: integer (nullable = true)\n |-- Disease: string (nullable = true)\n |-- age_group: string (nullable = false)\n |-- severity_level: string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# 1) Ensure numeric types\n",
    "df_clean = (\n",
    "    df_raw\n",
    "    .withColumn(\"Age\", col(\"Age\").cast(\"int\"))\n",
    "    .withColumn(\"Symptom_count\", col(\"Symptom_count\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "# 2) Create age_group from Age\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"Age\") < 18, \"Child\")\n",
    "    .when(col(\"Age\") < 40, \"Adult\")\n",
    "    .when(col(\"Age\") < 65, \"Middle-aged\")\n",
    "    .otherwise(\"Senior\")\n",
    ")\n",
    "\n",
    "# 3) Create severity_level from Symptom_count\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"severity_level\",\n",
    "    when(col(\"Symptom_count\") <= 2, \"Mild\")\n",
    "    .when(col(\"Symptom_count\") <= 5, \"Moderate\")\n",
    "    .otherwise(\"Severe\")\n",
    ")\n",
    "\n",
    "df_clean.show(5)\n",
    "df_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46e8b96e-1fd7-4b6b-8b8e-b2013478f9b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.write.mode(\"overwrite\").saveAsTable(\"final_exam_cluster.default.clean_healthcare\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingest_and_clean_healthcare",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}